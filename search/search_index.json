{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"K Container Shipment Order Management Service This project is demonstrating, one of the possible implementation of the Command Query Responsibility Segregation and event sourcing patterns applied to container shipment management service. It is part of the Event Driven Architecture reference architecture. From a use case point of view, it implements the order management for the order from the manufacturer to the shipping company of the K Container shipment process microservices. The business process is defined here . One of the business requirements for adopting event sourcing and CQRS patterns is to be able to get visibility to the history of orders and track the good shipment progress over time. This would include the ability to determine: How frequently does an order get cancelled after it is placed but before an empty container is delivered to pick up location or loaded ? How often does an order get cancelled after the order is confirmed, a container assigned and goods loaded into it? What are all events for a particular order and associated container shipment? Has the cold chain been protected on this particular order? How long it takes to deliver a container to pick up location? To answer the first question we need events like OrderPlaced(orderId), OrderCancelled(orderID) and in the read model the OrdersStatuses(orderId, status, timestamp); OrderStatusTransition(orderId, oldStatus, new Status timestamp) and then OrdersCancelledAfterPlaced(orderId, timestamp). We will detail how to implement those functions in later section. User stories The business requirements is presented in this note The following user stories are done in this project: [ ] As a manufacturer manager I want to enter container shipment order information like product reference, quantity, pickup from address, earliest pickup date, shipment to address, shipment by date, and required temperature in transit range so the shipping company can give me back an order confirmation ( including the orderID), expected pickup and delivery dates, the assigned voyage and ship name As the microservice will not have a dedicated UI, we are using the demonstration UI to define forms to gather the data. So this user story is implemented in the kc-ui project, and in this microservice we need to offer the create and update operations and get by order ID [ ] As a manufacturer manager I want to read the status of an order given its order id and receive a report with the full event history of related order, voyage ship and container events. The order id is generated by the order create operation, and is immutable. An order is assigned to a voyage at the time it is created. [ ] As a shipment company manager I want to update the status of an order, and add voyage, container and ship information once I know them, also possible modify pickup date and expected delivery date. [ ] As a shipment manager I want to be able to assign a shipment request from a customer to a specific voyage in order to create a confirmed order. The selected voyage must be from a source port near the pickup location travelling to a destination port near the delivery location requested by the customer. It must be within the time window specified by the customer in the order request. The selected voyage must have free space available ( capacity not previously assigned to other orders) to accomodate the number of containers specified by the customer in their shipment request. Same as above, the UI is in kc-ui project, so here is a model and the update operation. Implementation approach As introduced in the high level design note the order life cycle looks like in the following diagram: The order microservice supports the implementations of this life cycle, using event sourcing and CQRS. With CQRS we will separate the 'write model' from the read. The Command microservice implements the write model and exposes a set of REST end points for Creating Order, Updating Order and getting Order per ID. The query service will address complex queries to support adhoc business requirements and joining data between different entities like the order, the containers and the voyages. So we have two Java project to support each service implementation. Each service is packaged as container and deployable to Kubernetes. Order command microservice Order query microservice As some requirements are related to historical query, using an event approach we need to keep event on what happens to the order. Instead of implementing a complex logic with the query and command services the event sourcing is supported by using Kafka topics. The following diagram illustrates the CQRS and event sourcing applied to the order management service. Client to the REST api, like a back end for front end app, performs a HTTP POST operation with the order data. The command generates event and persist order on its own data source. The query part is a consumer of event and build its own projections to support the different queries: The datasource at the command level, may not be necessary, but we want to illustrate here the fact that it is possible to have a SQL based database or a document oriented database to keep the order last state: a call to get /orders/{id} will return the current order state. For the query part the projection can be kept in memory, depending of the amount of data to gather, and the view can be built by re-reading the event store. An alternate solution is to have the BFF pushing events to the event source and then having the order service consuming event to persist them, as illustrated in the following diagram: As the BFF still needs to get order by ID or perform complex query it has to access the order service using HTTP, we could image the BFF developers prefer to use one communication protocol and adding kafka producer was not their cup of tea. The following sequence diagram illustrates the relationships between the components. To avoid transaction between the database update and the event publisher, the choice is to publish the event as soon as it is received and use a consumer inside the command service to load the data and save to the database. This is illustrated in this article. The /order POST REST end point source code is here and the order events consumer in the command pattern. See the class OrderCRUDService.java . Produce order events to the orders topic. Consume events to update the state of the order or enrich it with new elements. When the application starts there is a ServletContextListener class started to create a consumer to subscribe to order events (different types) from orders topic. When consumer reaches an issue to get event it creates an error to the errors topic, so administrator user could replay the event source from the last committed offset. Any kafka broker communication issue is shutting down the consumer loop. Data and Event Model By applying a domain-driven design we can identify aggregates, entities, value objects and domain events. Those elements help us to be our information model as classes. For any event-driven microservice you need to assess what data to carry in the event and what persist in the potential data source. The following diagram illustrates the different data models in the context of this order microservice: The Order entered in the User interface is defined like: class Address { street: string; city: string; country: string; state: string; zipcode: string; } class Order { orderID: string; customerID: string; pickupAddress: Address; destinationAddress: Address; productID: string; quantity: string; expectedDeliveryDate: string; // date as ISO format } The information to persist in the database may be used to do analytics, and get the last status of order. It may look use relational database and may have information like: class Address { street: string; city: string; country: string; state: string; zipcode: string; } class Order { orderID: string; customerID: string; pickupAddress: Address; destinationAddress: Address; productID: string; quantity: string; expectedDeliveryDate: string; // date as ISO format pickupDate: string; // date as ISO format } class OrderContainers { orderID: string; containerID: string[]; } On the event side we may generate OrderCreated, OrderCancelled,... But what is in the event payload? We can propose the following structure where type will help to specify the event type and getting a generic payload we can have anything in it. class OrderEvent { orderId: string; timestamp: string; // date as ISO format payload: any; type: string; version: string; } Also do we need to ensure consistency between those data views? Where is the source of truth? In traditional SOA service with application maintaining all the tables and beans to support all the business requirements, ACID transactions support the consistency and integrity of the data, and the database is one source of truth. With microservices responsible to manage its own business entity, clearly separated from other business entities, data eventual consistency is the standard. If you want to read more about the Event Sourcing and CQRS patterns see this article. How to build and run Pre-requisites You can have the following installed on your computer or use our docker image to get those dependencies integrated in a docker image and you can use to build, test and package the java programs. Maven Java 8: Any compliant JVM should work. * Java 8 JDK from Oracle * Java 8 JDK from IBM (AIX, Linux, z/OS, IBM i) , or Download a Liberty server package that contains the IBM JDK (Windows, Linux) Build Each microservice has a build script to perform the maven package and build the docker image. See scripts folder. For order-command-ms ./scripts/buildDocker.sh For order-query-ms ./scripts/buildDocker.sh To build without docker image: mvn install or mvn install -DskipITs to bypass integration tests, as they need kafka and a running Liberty server Run You can start the Liberty server locally with mvn liberty:run-server to start the server with the deployed wars. Or run the complete solution locally using docker compose from the refarck-kc project to start a local kafka broker and all the components: One time execution of the kafka broker: cd refarch-kc/docker docker-compose -f backbone-compose.yml up Start the solution docker-compose -f bkc-solution-compose.yml up And stop everything: docker-compose -f kc-solution-compose.yml down docker-compose -f backbone-compose.yml down","title":"Implementation considerations, build, run"},{"location":"#k-container-shipment-order-management-service","text":"This project is demonstrating, one of the possible implementation of the Command Query Responsibility Segregation and event sourcing patterns applied to container shipment management service. It is part of the Event Driven Architecture reference architecture. From a use case point of view, it implements the order management for the order from the manufacturer to the shipping company of the K Container shipment process microservices. The business process is defined here . One of the business requirements for adopting event sourcing and CQRS patterns is to be able to get visibility to the history of orders and track the good shipment progress over time. This would include the ability to determine: How frequently does an order get cancelled after it is placed but before an empty container is delivered to pick up location or loaded ? How often does an order get cancelled after the order is confirmed, a container assigned and goods loaded into it? What are all events for a particular order and associated container shipment? Has the cold chain been protected on this particular order? How long it takes to deliver a container to pick up location? To answer the first question we need events like OrderPlaced(orderId), OrderCancelled(orderID) and in the read model the OrdersStatuses(orderId, status, timestamp); OrderStatusTransition(orderId, oldStatus, new Status timestamp) and then OrdersCancelledAfterPlaced(orderId, timestamp). We will detail how to implement those functions in later section.","title":"K Container Shipment Order Management Service"},{"location":"#user-stories","text":"The business requirements is presented in this note The following user stories are done in this project: [ ] As a manufacturer manager I want to enter container shipment order information like product reference, quantity, pickup from address, earliest pickup date, shipment to address, shipment by date, and required temperature in transit range so the shipping company can give me back an order confirmation ( including the orderID), expected pickup and delivery dates, the assigned voyage and ship name As the microservice will not have a dedicated UI, we are using the demonstration UI to define forms to gather the data. So this user story is implemented in the kc-ui project, and in this microservice we need to offer the create and update operations and get by order ID [ ] As a manufacturer manager I want to read the status of an order given its order id and receive a report with the full event history of related order, voyage ship and container events. The order id is generated by the order create operation, and is immutable. An order is assigned to a voyage at the time it is created. [ ] As a shipment company manager I want to update the status of an order, and add voyage, container and ship information once I know them, also possible modify pickup date and expected delivery date. [ ] As a shipment manager I want to be able to assign a shipment request from a customer to a specific voyage in order to create a confirmed order. The selected voyage must be from a source port near the pickup location travelling to a destination port near the delivery location requested by the customer. It must be within the time window specified by the customer in the order request. The selected voyage must have free space available ( capacity not previously assigned to other orders) to accomodate the number of containers specified by the customer in their shipment request. Same as above, the UI is in kc-ui project, so here is a model and the update operation.","title":"User stories"},{"location":"#implementation-approach","text":"As introduced in the high level design note the order life cycle looks like in the following diagram: The order microservice supports the implementations of this life cycle, using event sourcing and CQRS. With CQRS we will separate the 'write model' from the read. The Command microservice implements the write model and exposes a set of REST end points for Creating Order, Updating Order and getting Order per ID. The query service will address complex queries to support adhoc business requirements and joining data between different entities like the order, the containers and the voyages. So we have two Java project to support each service implementation. Each service is packaged as container and deployable to Kubernetes. Order command microservice Order query microservice As some requirements are related to historical query, using an event approach we need to keep event on what happens to the order. Instead of implementing a complex logic with the query and command services the event sourcing is supported by using Kafka topics. The following diagram illustrates the CQRS and event sourcing applied to the order management service. Client to the REST api, like a back end for front end app, performs a HTTP POST operation with the order data. The command generates event and persist order on its own data source. The query part is a consumer of event and build its own projections to support the different queries: The datasource at the command level, may not be necessary, but we want to illustrate here the fact that it is possible to have a SQL based database or a document oriented database to keep the order last state: a call to get /orders/{id} will return the current order state. For the query part the projection can be kept in memory, depending of the amount of data to gather, and the view can be built by re-reading the event store. An alternate solution is to have the BFF pushing events to the event source and then having the order service consuming event to persist them, as illustrated in the following diagram: As the BFF still needs to get order by ID or perform complex query it has to access the order service using HTTP, we could image the BFF developers prefer to use one communication protocol and adding kafka producer was not their cup of tea. The following sequence diagram illustrates the relationships between the components. To avoid transaction between the database update and the event publisher, the choice is to publish the event as soon as it is received and use a consumer inside the command service to load the data and save to the database. This is illustrated in this article. The /order POST REST end point source code is here and the order events consumer in the command pattern. See the class OrderCRUDService.java . Produce order events to the orders topic. Consume events to update the state of the order or enrich it with new elements. When the application starts there is a ServletContextListener class started to create a consumer to subscribe to order events (different types) from orders topic. When consumer reaches an issue to get event it creates an error to the errors topic, so administrator user could replay the event source from the last committed offset. Any kafka broker communication issue is shutting down the consumer loop.","title":"Implementation approach"},{"location":"#data-and-event-model","text":"By applying a domain-driven design we can identify aggregates, entities, value objects and domain events. Those elements help us to be our information model as classes. For any event-driven microservice you need to assess what data to carry in the event and what persist in the potential data source. The following diagram illustrates the different data models in the context of this order microservice: The Order entered in the User interface is defined like: class Address { street: string; city: string; country: string; state: string; zipcode: string; } class Order { orderID: string; customerID: string; pickupAddress: Address; destinationAddress: Address; productID: string; quantity: string; expectedDeliveryDate: string; // date as ISO format } The information to persist in the database may be used to do analytics, and get the last status of order. It may look use relational database and may have information like: class Address { street: string; city: string; country: string; state: string; zipcode: string; } class Order { orderID: string; customerID: string; pickupAddress: Address; destinationAddress: Address; productID: string; quantity: string; expectedDeliveryDate: string; // date as ISO format pickupDate: string; // date as ISO format } class OrderContainers { orderID: string; containerID: string[]; } On the event side we may generate OrderCreated, OrderCancelled,... But what is in the event payload? We can propose the following structure where type will help to specify the event type and getting a generic payload we can have anything in it. class OrderEvent { orderId: string; timestamp: string; // date as ISO format payload: any; type: string; version: string; } Also do we need to ensure consistency between those data views? Where is the source of truth? In traditional SOA service with application maintaining all the tables and beans to support all the business requirements, ACID transactions support the consistency and integrity of the data, and the database is one source of truth. With microservices responsible to manage its own business entity, clearly separated from other business entities, data eventual consistency is the standard. If you want to read more about the Event Sourcing and CQRS patterns see this article.","title":"Data and Event Model"},{"location":"#how-to-build-and-run","text":"","title":"How to build and run"},{"location":"#pre-requisites","text":"You can have the following installed on your computer or use our docker image to get those dependencies integrated in a docker image and you can use to build, test and package the java programs. Maven Java 8: Any compliant JVM should work. * Java 8 JDK from Oracle * Java 8 JDK from IBM (AIX, Linux, z/OS, IBM i) , or Download a Liberty server package that contains the IBM JDK (Windows, Linux)","title":"Pre-requisites"},{"location":"#build","text":"Each microservice has a build script to perform the maven package and build the docker image. See scripts folder. For order-command-ms ./scripts/buildDocker.sh For order-query-ms ./scripts/buildDocker.sh To build without docker image: mvn install or mvn install -DskipITs to bypass integration tests, as they need kafka and a running Liberty server","title":"Build"},{"location":"#run","text":"You can start the Liberty server locally with mvn liberty:run-server to start the server with the deployed wars. Or run the complete solution locally using docker compose from the refarck-kc project to start a local kafka broker and all the components: One time execution of the kafka broker: cd refarch-kc/docker docker-compose -f backbone-compose.yml up Start the solution docker-compose -f bkc-solution-compose.yml up And stop everything: docker-compose -f kc-solution-compose.yml down docker-compose -f backbone-compose.yml down","title":"Run"},{"location":"deployments/","text":"Deployments Deploy to IKS Deploy to ICP","title":"Deployments"},{"location":"deployments/#deployments","text":"","title":"Deployments"},{"location":"deployments/#deploy-to-iks","text":"","title":"Deploy to IKS"},{"location":"deployments/#deploy-to-icp","text":"","title":"Deploy to ICP"}]}